2023-03-20 06:08:34,315 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting DataNode
STARTUP_MSG:   host = dn1/10.2.0.5
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.2
STARTUP_MSG:   classpath = /hadoop/hadoop-3.1.2/etc/hadoop:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jsch-0.1.54.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jersey-core-1.19.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-math3-3.1.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/re2j-1.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jersey-json-1.19.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-cli-1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-2.7.8.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-lang-2.6.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerby-config-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/snappy-java-1.0.5.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/json-smart-2.3.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/log4j-1.2.17.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-collections-3.2.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/stax2-api-3.1.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerby-util-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerb-server-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-compress-1.18.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/curator-framework-2.13.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jersey-servlet-1.19.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerb-common-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jsr305-3.0.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/avro-1.7.7.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-net-3.6.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/guava-11.0.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/accessors-smart-1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jsp-api-2.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jettison-1.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-io-2.5.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/metrics-core-3.2.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerb-core-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/token-provider-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/httpcore-4.4.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-codec-1.11.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/netty-3.10.5.Final.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/gson-2.2.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/hadoop-auth-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/hadoop-annotations-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerb-client-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/curator-client-2.13.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-logging-1.1.3.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerb-util-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/zookeeper-3.4.13.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/commons-lang3-3.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/httpclient-4.5.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/paranamer-2.3.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/asm-5.0.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jersey-server-1.19.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/hadoop-common-3.1.2-tests.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/hadoop-kms-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/hadoop-nfs-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/aspectjrt-1.9.6.jar:/hadoop/hadoop-3.1.2/share/hadoop/common/reditrt-0.1.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/re2j-1.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/json-smart-2.3.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/avro-1.7.7.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-net-3.6.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/guava-11.0.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jettison-1.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-io-2.5.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/okio-1.6.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/gson-2.2.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-auth-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/hadoop-annotations-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/paranamer-2.3.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/asm-5.0.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2-tests.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-client-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-3.1.2-tests.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2-tests.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.2-tests.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/lib/junit-4.11.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2-tests.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/aopalliance-1.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/fst-2.50.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/javax.inject-1.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/java-util-1.9.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/objenesis-1.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/guice-4.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/jersey-client-1.19.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/json-io-2.5.1.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-router-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-core-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-services-api-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-client-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-api-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-registry-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-common-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-common-3.1.2.jar:/hadoop/hadoop-3.1.2/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.2.jar
STARTUP_MSG:   build = https://github.com/apache/hadoop.git -r 1019dde65bcf12e05ef48ac71e84550d589e5d9a; compiled by 'sunilg' on 2019-01-29T01:39Z
STARTUP_MSG:   java = 1.8.0_242
************************************************************/
2023-03-20 06:08:34,318 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
2023-03-20 06:08:34,401 WARN org.apache.hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2023-03-20 06:08:34,470 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for [DISK]file:/var/lib/hdfs/data
2023-03-20 06:08:34,548 INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
2023-03-20 06:08:34,578 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-03-20 06:08:34,579 INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
2023-03-20 06:08:34,694 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-03-20 06:08:34,695 INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
2023-03-20 06:08:34,698 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is dn1
2023-03-20 06:08:34,698 INFO org.apache.hadoop.hdfs.server.common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2023-03-20 06:08:34,701 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
2023-03-20 06:08:34,712 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
2023-03-20 06:08:34,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
2023-03-20 06:08:34,754 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
2023-03-20 06:08:34,775 INFO org.eclipse.jetty.util.log: Logging initialized @678ms
2023-03-20 06:08:34,828 INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2023-03-20 06:08:34,829 INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
2023-03-20 06:08:34,834 INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2023-03-20 06:08:34,835 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2023-03-20 06:08:34,835 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2023-03-20 06:08:34,835 INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2023-03-20 06:08:34,848 INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 43717
2023-03-20 06:08:34,849 INFO org.eclipse.jetty.server.Server: jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2023-03-20 06:08:34,866 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@7bf3a5d8{/logs,file:///hadoop/hadoop-3.1.2/logs/,AVAILABLE}
2023-03-20 06:08:34,866 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.s.ServletContextHandler@39b43d60{/static,file:///hadoop/hadoop-3.1.2/share/hadoop/hdfs/webapps/static/,AVAILABLE}
2023-03-20 06:08:34,959 INFO org.eclipse.jetty.server.handler.ContextHandler: Started o.e.j.w.WebAppContext@3e74829{/,file:///hadoop/hadoop-3.1.2/share/hadoop/hdfs/webapps/datanode/,AVAILABLE}{/datanode}
2023-03-20 06:08:34,963 INFO org.eclipse.jetty.server.AbstractConnector: Started ServerConnector@52d6d1d6{HTTP/1.1,[http/1.1]}{localhost:43717}
2023-03-20 06:08:34,963 INFO org.eclipse.jetty.server.Server: Started @867ms
2023-03-20 06:08:35,034 INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
2023-03-20 06:08:35,037 INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
2023-03-20 06:08:35,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = root
2023-03-20 06:08:35,038 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
2023-03-20 06:08:35,055 INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2023-03-20 06:08:35,060 INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
2023-03-20 06:08:35,158 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
2023-03-20 06:08:35,168 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: mycluster
2023-03-20 06:08:35,175 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: mycluster
2023-03-20 06:08:35,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to nn2/10.2.0.4:8020 starting to offer service
2023-03-20 06:08:35,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to nn3/10.2.0.3:8020 starting to offer service
2023-03-20 06:08:35,180 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to nn1/10.2.0.2:8020 starting to offer service
2023-03-20 06:08:35,183 INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
2023-03-20 06:08:35,184 INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
2023-03-20 06:08:35,320 INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
2023-03-20 06:08:35,328 INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /var/lib/hdfs/data/in_use.lock acquired by nodename 48@dn1
2023-03-20 06:08:35,329 INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory with location [DISK]file:/var/lib/hdfs/data is not formatted for namespace 2026443485. Formatting...
2023-03-20 06:08:35,329 INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-555b3338-4c0c-416b-86ed-513ab4f487fb for directory /var/lib/hdfs/data 
2023-03-20 06:08:35,357 INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-816139872-10.2.0.2-1679292508807
2023-03-20 06:08:35,357 INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /var/lib/hdfs/data/current/BP-816139872-10.2.0.2-1679292508807
2023-03-20 06:08:35,357 INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory for location [DISK]file:/var/lib/hdfs/data and block pool id BP-816139872-10.2.0.2-1679292508807 is not formatted. Formatting ...
2023-03-20 06:08:35,358 INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-816139872-10.2.0.2-1679292508807 directory /var/lib/hdfs/data/current/BP-816139872-10.2.0.2-1679292508807/current
2023-03-20 06:08:35,369 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=2026443485;bpid=BP-816139872-10.2.0.2-1679292508807;lv=-57;nsInfo=lv=-64;cid=CID-fad9de24-8f6d-4a83-95c0-6113687b1542;nsid=2026443485;c=1679292508807;bpid=BP-816139872-10.2.0.2-1679292508807;dnuuid=null
2023-03-20 06:08:35,375 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID 6a920ac2-f9bb-4d9b-bc31-1a0e93a69748
2023-03-20 06:08:35,415 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-555b3338-4c0c-416b-86ed-513ab4f487fb
2023-03-20 06:08:35,416 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - [DISK]file:/var/lib/hdfs/data, StorageType: DISK
2023-03-20 06:08:35,419 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
2023-03-20 06:08:35,424 INFO org.apache.hadoop.hdfs.server.datanode.checker.ThrottledAsyncChecker: Scheduling a check for /var/lib/hdfs/data
2023-03-20 06:08:35,430 INFO org.apache.hadoop.hdfs.server.datanode.checker.DatasetVolumeChecker: Scheduled health check for volume /var/lib/hdfs/data
2023-03-20 06:08:35,431 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-816139872-10.2.0.2-1679292508807
2023-03-20 06:08:35,431 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-816139872-10.2.0.2-1679292508807 on volume /var/lib/hdfs/data...
2023-03-20 06:08:35,452 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-816139872-10.2.0.2-1679292508807 on /var/lib/hdfs/data: 21ms
2023-03-20 06:08:35,452 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-816139872-10.2.0.2-1679292508807: 21ms
2023-03-20 06:08:35,454 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-816139872-10.2.0.2-1679292508807 on volume /var/lib/hdfs/data...
2023-03-20 06:08:35,454 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /var/lib/hdfs/data/current/BP-816139872-10.2.0.2-1679292508807/current/replicas doesn't exist 
2023-03-20 06:08:35,455 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-816139872-10.2.0.2-1679292508807 on volume /var/lib/hdfs/data: 0ms
2023-03-20 06:08:35,455 INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map for block pool BP-816139872-10.2.0.2-1679292508807: 2ms
2023-03-20 06:08:35,456 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-816139872-10.2.0.2-1679292508807 on volume /var/lib/hdfs/data
2023-03-20 06:08:35,457 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/var/lib/hdfs/data, DS-555b3338-4c0c-416b-86ed-513ab4f487fb): finished scanning block pool BP-816139872-10.2.0.2-1679292508807
2023-03-20 06:08:35,461 INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 3/20/23 12:03 PM with interval of 21600000ms
2023-03-20 06:08:35,465 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-816139872-10.2.0.2-1679292508807 (Datanode Uuid 6a920ac2-f9bb-4d9b-bc31-1a0e93a69748) service to nn1/10.2.0.2:8020 beginning handshake with NN
2023-03-20 06:08:35,470 INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/var/lib/hdfs/data, DS-555b3338-4c0c-416b-86ed-513ab4f487fb): no suitable block pools found to scan.  Waiting 1814399986 ms.
2023-03-20 06:08:35,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-816139872-10.2.0.2-1679292508807 (Datanode Uuid 6a920ac2-f9bb-4d9b-bc31-1a0e93a69748) service to nn1/10.2.0.2:8020 successfully registered with NN
2023-03-20 06:08:35,513 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode nn1/10.2.0.2:8020 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-03-20 06:08:35,584 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x8e6c5979e4b02444,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 27 msecs for RPC and NN processing. Got back no commands.
2023-03-20 06:08:36,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: nn2/10.2.0.4:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-03-20 06:08:36,225 INFO org.apache.hadoop.ipc.Client: Retrying connect to server: nn3/10.2.0.3:8020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2023-03-20 06:08:36,226 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-816139872-10.2.0.2-1679292508807 (Datanode Uuid 6a920ac2-f9bb-4d9b-bc31-1a0e93a69748) service to nn2/10.2.0.4:8020 beginning handshake with NN
2023-03-20 06:08:36,227 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-816139872-10.2.0.2-1679292508807 (Datanode Uuid 6a920ac2-f9bb-4d9b-bc31-1a0e93a69748) service to nn3/10.2.0.3:8020 beginning handshake with NN
2023-03-20 06:08:36,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-816139872-10.2.0.2-1679292508807 (Datanode Uuid 6a920ac2-f9bb-4d9b-bc31-1a0e93a69748) service to nn2/10.2.0.4:8020 successfully registered with NN
2023-03-20 06:08:36,228 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode nn2/10.2.0.4:8020 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-03-20 06:08:36,230 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xd52bf0cc64ffb7a8,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back no commands.
2023-03-20 06:08:36,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-816139872-10.2.0.2-1679292508807 (Datanode Uuid 6a920ac2-f9bb-4d9b-bc31-1a0e93a69748) service to nn3/10.2.0.3:8020 successfully registered with NN
2023-03-20 06:08:36,234 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode nn3/10.2.0.3:8020 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2023-03-20 06:08:36,297 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xa482a27750fd138,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 45 msecs for RPC and NN processing. Got back no commands.
2023-03-20 06:08:53,378 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: dn1:9866:DataXceiverServer: 
java.io.IOException: Xceiver count 1 exceeds the limit of concurrent xcievers: -1
	at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:150)
	at java.lang.Thread.run(Thread.java:748)
2023-03-20 06:08:53,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-816139872-10.2.0.2-1679292508807 (Datanode Uuid 6a920ac2-f9bb-4d9b-bc31-1a0e93a69748) service to nn1/10.2.0.2:8020 trying to claim ACTIVE state with txid=10
2023-03-20 06:08:53,518 INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-816139872-10.2.0.2-1679292508807 (Datanode Uuid 6a920ac2-f9bb-4d9b-bc31-1a0e93a69748) service to nn1/10.2.0.2:8020
2023-03-20 06:10:26,383 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.IOException: DestHost:destPort nn1:8020 , LocalHost:localPort dn1/10.2.0.5:0. Failed on local exception: java.io.IOException: Connection reset by peer
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:842)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:377)
	at org.apache.hadoop.net.SocketInputStream$Reader.performIO(SocketInputStream.java:57)
	at org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:142)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)
	at org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at java.io.FilterInputStream.read(FilterInputStream.java:83)
	at org.apache.hadoop.ipc.Client$Connection$PingInputStream.read(Client.java:557)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2023-03-20 06:10:27,234 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "dn1/10.2.0.5"; destination host is: "nn2":8020; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:789)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:842)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2023-03-20 06:10:27,241 WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
java.io.EOFException: End of File Exception between local host is: "dn1/10.2.0.5"; destination host is: "nn3":8020; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:789)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy19.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:166)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:514)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:645)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:842)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
